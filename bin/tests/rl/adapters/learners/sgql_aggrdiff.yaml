? &id002 !!burlap.statehashing.simple.IDSimpleHashableState
  s: &id001 !!rl.models.aggregatediff.AggregateDiffState {barracksDiff: AHEAD, basesDiff: EVEN,
    heavyDiff: AHEAD, lightDiff: BEHIND, rangedDiff: BEHIND, resourcesDiff: AHEAD,
    stage: OPENING, workerDiff: AHEAD}
: !!burlap.behavior.singleagent.learning.tdmethods.QLearningStateNode
  qEntry:
  - a: &id003 !!burlap.mdp.core.action.SimpleAction {name: LightRush}
    q: 0.7
    s: *id001
  - a: &id005 !!burlap.mdp.core.action.SimpleAction {name: BuildBarracks}
    q: 0.6
    s: *id001
  - a: &id006 !!burlap.mdp.core.action.SimpleAction {name: RangedRush}
    q: -0.9
    s: *id001
  - a: &id007 !!burlap.mdp.core.action.SimpleAction {name: Expand}
    q: 1.0
    s: *id001
  - a: &id008 !!burlap.mdp.core.action.SimpleAction {name: WorkerRush}
    q: 1.0
    s: *id001
  s: *id002
? &id009 !!burlap.statehashing.simple.IDSimpleHashableState
  s: &id004 !!rl.models.aggregatediff.AggregateDiffState {barracksDiff: EVEN, basesDiff: EVEN,
    heavyDiff: EVEN, lightDiff: AHEAD, rangedDiff: BEHIND, resourcesDiff: EVEN, stage: END,
    workerDiff: EVEN}
: !!burlap.behavior.singleagent.learning.tdmethods.QLearningStateNode
  qEntry:
  - a: *id003
    q: 1.0
    s: *id004
  - a: *id005
    q: 1.0
    s: *id004
  - a: *id006
    q: 1.0
    s: *id004
  - a: *id007
    q: 0.33
    s: *id004
  - a: *id008
    q: -0.5
    s: *id004
  s: *id009
